Objective

Restructure the existing trading agent codebase to improve maintainability, enable parallel development, and ensure compatibility with the Replit deployment environment. The goal is to separate concerns while keeping all components interoperable.

Core Requirements

Introduce the following new modular components:

core/training.py → Training execution
core/hyperparameter_tuning.py → Optuna optimization
core/testing.py → Model evaluation
core/orchestrator.py → Component coordination (execution pipeline)
config.py → Centralized parameter management
Each module should be self-contained and replace the specific code sections that are performing this. I do not need to add any performance improvements now, simply to restructure the code for better modularity.

Data Flow Architecture

Training → Orchestrator → Testing Pipeline
Shared state management via Streamlit session (st.session_state).
All parameters must be handled through config.py, avoiding hardcoded values.
Implementation Guidelines

1. Configuration Management (config.py)
All training, optimization, and testing parameters should be stored in a centralized file. Example structure:

TRAINING_CONFIG = {
    "initial_balance": 10000,
    "transaction_cost": 0.01,
    "portfolio_action_scheme": "discrete",
    "max_position_size": 1.0
}

OPTIMIZATION_CONFIG = {
    "n_trials": 20,
    "metric": "sharpe_ratio",
    "pruning_enabled": True
}

TESTING_CONFIG = {
    "evaluation_period_days": 365,
    "metrics": ["sharpe_ratio", "max_drawdown", "win_rate"]
}
This ensures consistency and makes parameter adjustments straightforward.

2. Key Components and Responsibilities

a) Training Module (core/training.py)
Manages training execution using predefined parameters.
Handles progress tracking and performance metric calculations.
Interfaces with orchestrator.py for controlled execution.
b) Optimization Module (core/hyperparameter_tuning.py)
Implements Optuna-based hyperparameter tuning.
Saves optimal parameters to config.py.
c) Testing Module (core/testing.py)
Runs model evaluation and performance tracking.
Visualizes results, trade history, and metrics.
d) Orchestrator (core/orchestrator.py)
Manages execution flow across all components.
Calls run_training() from core/training.py.
Calls hyperparameter_tuning() from core/hyperparameter_tuning.py.
Calls display_testing_interface() from core/testing.py.
Ensures proper data exchange between modules.

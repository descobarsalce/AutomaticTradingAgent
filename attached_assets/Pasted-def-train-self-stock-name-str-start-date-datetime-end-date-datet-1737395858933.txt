def train(self,
          stock_name: str,
          start_date: datetime,
          end_date: datetime,
          env_params: Dict[str, Any],
          ppo_params: Dict[str, Any],
          callback=None) -> Dict[str, float]:
    """
    Train the PPO agent within the specified time frame using the given environment and parameters.
    """
    # Prepare data and initialize environment
    data = self.prepare_training_data(stock_name, start_date, end_date)
    self.initialize_env(data, env_params)

    # Validate PPO parameters
    learning_rate = ppo_params.get('learning_rate', 3e-4)
    decay_steps = ppo_params.get('decay_steps', 1000)
    decay_rate = ppo_params.get('decay_rate', 0.95)

    # Create learning rate schedule
    learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=learning_rate,
        decay_steps=decay_steps,
        decay_rate=decay_rate
    )

    # Update PPO parameters with the schedule
    ppo_params['learning_rate'] = learning_rate_schedule

    # Initialize the TradingAgent with updated PPO parameters
    self.agent = TradingAgent(env=self.env, ppo_params=ppo_params)

    # Define training duration
    total_timesteps = (end_date - start_date).days * env_params.get('steps_per_day', 1)

    # Train the agent
    self.agent.train(total_timesteps=total_timesteps, callback=callback)

    # Save the trained model
    self.agent.save("trained_model.zip")

    # Calculate metrics
    self.portfolio_history = self.env.get_portfolio_history()
    if len(self.portfolio_history) > 1:
        returns = MetricsCalculator.calculate_returns(self.portfolio_history)
        return {
            'sharpe_ratio': MetricsCalculator.calculate_sharpe_ratio(returns),
            'max_drawdown': MetricsCalculator.calculate_maximum_drawdown(self.portfolio_history),
            'sortino_ratio': MetricsCalculator.calculate_sortino_ratio(returns),
            'volatility': MetricsCalculator.calculate_volatility(returns),
            'total_return': (self.portfolio_history[-1] - self.portfolio_history[0]) / self.portfolio_history[0],
            'final_value': self.portfolio_history[-1]
        }
    return {}
